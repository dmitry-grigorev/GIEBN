{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий код между ноутбуками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(data, variables, icat, icont, contdiscstrategy=\"kmeans\", n_bins=3):\n",
    "    transformers_data = dict()\n",
    "    \n",
    "    if icat is None: # в датасете только непрерывные фичи (и предиктор)\n",
    "        pipeline = make_pipeline(\n",
    "            KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", random_state=42, strategy=contdiscstrategy), \n",
    "            FunctionTransformer(lambda x: x.astype(\"int\")))\n",
    "    elif icont is None: # в датасете только категориальные фичи (и предиктор)\n",
    "        pipeline = make_pipeline(\n",
    "            OrdinalEncoder(categories=\"auto\"), \n",
    "            FunctionTransformer(lambda x: x.astype(\"int\")))\n",
    "    else:\n",
    "        pipeline = make_pipeline(make_union(\n",
    "        make_pipeline(FunctionTransformer(lambda x: x.iloc[:, icat]), OrdinalEncoder(categories=\"auto\")),\n",
    "        make_pipeline(FunctionTransformer(lambda x: x.loc[:, icont]), KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", random_state=42, strategy=contdiscstrategy))\n",
    "    ),\n",
    "        FunctionTransformer(lambda x: x.astype(\"int\")))\n",
    "    \n",
    "    \n",
    "    pipeline.fit(data)\n",
    "    encoded_data = pd.DataFrame(pipeline.transform(data), columns=data.columns if icat is None or icont is None\\\n",
    "                                                                                        else data.columns[icat+icont])\n",
    "    encoded_data = encoded_data[variables] # в общем случае пайплайн переставляет признаки, возвращаем их на их места здесь\n",
    "\n",
    "    for feat in encoded_data.columns:\n",
    "        if entropy(encoded_data[feat]) < 0.5:\n",
    "            print(f\"Warning: feature {feat} has practically degenerate states and low entropy\")\n",
    "    transformers_data[\"transformer\"] = pipeline\n",
    "    \n",
    "    if icat is None:\n",
    "        transformers_data[\"cont_features\"]       = list(pipeline.steps[0][1].get_feature_names_out())\n",
    "        transformers_data[\"cont_features_edges\"] = pipeline.steps[0][1].bin_edges_\n",
    "        \n",
    "    elif icont is None:\n",
    "        transformers_data[\"cat_features\"]            = list(pipeline.steps[0][1].get_feature_names_out())\n",
    "        transformers_data[\"cat_features_categories\"] = pipeline.steps[0][1].categories_\n",
    "        \n",
    "    else:\n",
    "        transformers_data[\"cont_features\"]           = list(pipeline.steps[0][1].named_transformers[\"pipeline-2\"].steps[1][1].get_feature_names_out())\n",
    "        transformers_data[\"cont_features_edges\"]     = pipeline.steps[0][1].named_transformers[\"pipeline-2\"].steps[1][1].bin_edges_\n",
    "        transformers_data[\"cat_features\"]            = list(pipeline.steps[0][1].named_transformers[\"pipeline-1\"].steps[1][1].get_feature_names_out())\n",
    "        transformers_data[\"cat_features_categories\"] = pipeline.steps[0][1].named_transformers[\"pipeline-1\"].steps[1][1].categories_\n",
    "    \n",
    "    #kmeanspipeline.steps[0][1].named_transformers[\"pipeline-1\"].steps[1][1].categories_[0]\n",
    "    return encoded_data, transformers_data\n",
    "\n",
    "#disc_data, pipeline_data = discretize(data, variables, icat=None, icont=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_cpds(bn_info, distributions, n_states_map):\n",
    "    cpds = list()\n",
    "    for index, row in bn_info.iterrows():\n",
    "        feat = row[\"name\"].name\n",
    "        if len(row[\"parents\"]) == 0:\n",
    "            # cpd is just a pd\n",
    "            cpd = TabularCPD(feat, n_states_map[feat], [[e] for e in distributions[feat][\"cprob\"]])\n",
    "            cpds.append(cpd)\n",
    "        else:\n",
    "            cpd_list = [probs for probs in distributions[feat][\"cprob\"].values()]\n",
    "            #cpd_list = [probs for i, probs in distributions[feat][\"cprob\"].items() if i[0]!=\"[\"]\n",
    "            #print(cpd_list)\n",
    "            nrows = len(cpd_list)\n",
    "            ncols = len(cpd_list[0])\n",
    "            cpd_list = [[cpd_list[i][j] for i in range(nrows)] for j in range(ncols)]\n",
    "            #print(feat, row[\"parents\"])\n",
    "            #print(cpd_list)\n",
    "            cpd = TabularCPD(feat, n_states_map[feat], cpd_list, evidence=row[\"parents\"], evidence_card=[n_states_map[p] for p in row[\"parents\"]])\n",
    "            cpds.append(cpd)\n",
    "    return cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
