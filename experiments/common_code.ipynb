{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий код между ноутбуками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дискретизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(a):\n",
    "    vc = a.value_counts()\n",
    "    vc/=vc.sum()\n",
    "    return -(vc*np.log(vc)).sum()\n",
    "\n",
    "def discretize(data, variables, icat, icont, contdiscstrategy=\"kmeans\", n_bins=3):\n",
    "    transformers_data = dict()\n",
    "    \n",
    "    if icat is None: # в датасете только непрерывные фичи (и предиктор)\n",
    "        pipeline = make_pipeline(\n",
    "            KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", random_state=42, strategy=contdiscstrategy), \n",
    "            FunctionTransformer(lambda x: x.astype(\"int\")))\n",
    "    elif icont is None: # в датасете только категориальные фичи (и предиктор)\n",
    "        pipeline = make_pipeline(\n",
    "            OrdinalEncoder(categories=\"auto\"), \n",
    "            FunctionTransformer(lambda x: x.astype(\"int\")))\n",
    "    else:\n",
    "        pipeline = make_pipeline(make_union(\n",
    "        make_pipeline(FunctionTransformer(lambda x: x.iloc[:, icat]), OrdinalEncoder(categories=\"auto\")),\n",
    "        make_pipeline(FunctionTransformer(lambda x: x.loc[:, icont]), KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", random_state=42, strategy=contdiscstrategy))\n",
    "    ),\n",
    "        FunctionTransformer(lambda x: x.astype(\"int\")))\n",
    "    \n",
    "    \n",
    "    pipeline.fit(data)\n",
    "    encoded_data = pd.DataFrame(pipeline.transform(data), columns=data.columns if icat is None or icont is None\\\n",
    "                                                                                        else data.columns[icat+icont])\n",
    "    encoded_data = encoded_data[variables] # в общем случае пайплайн переставляет признаки, возвращаем их на их места здесь\n",
    "\n",
    "    for feat in encoded_data.columns:\n",
    "        if entropy(encoded_data[feat]) < 0.5:\n",
    "            print(f\"Warning: feature {feat} has practically degenerate states and low entropy\")\n",
    "    transformers_data[\"transformer\"] = pipeline\n",
    "    \n",
    "    if icat is None:\n",
    "        transformers_data[\"cont_features\"]       = list(pipeline.steps[0][1].get_feature_names_out())\n",
    "        transformers_data[\"cont_features_edges\"] = pipeline.steps[0][1].bin_edges_\n",
    "        \n",
    "    elif icont is None:\n",
    "        transformers_data[\"cat_features\"]            = list(pipeline.steps[0][1].get_feature_names_out())\n",
    "        transformers_data[\"cat_features_categories\"] = pipeline.steps[0][1].categories_\n",
    "        \n",
    "    else:\n",
    "        transformers_data[\"cont_features\"]           = list(pipeline.steps[0][1].named_transformers[\"pipeline-2\"].steps[1][1].get_feature_names_out())\n",
    "        transformers_data[\"cont_features_edges\"]     = pipeline.steps[0][1].named_transformers[\"pipeline-2\"].steps[1][1].bin_edges_\n",
    "        transformers_data[\"cat_features\"]            = list(pipeline.steps[0][1].named_transformers[\"pipeline-1\"].steps[1][1].get_feature_names_out())\n",
    "        transformers_data[\"cat_features_categories\"] = pipeline.steps[0][1].named_transformers[\"pipeline-1\"].steps[1][1].categories_\n",
    "    \n",
    "    #kmeanspipeline.steps[0][1].named_transformers[\"pipeline-1\"].steps[1][1].categories_[0]\n",
    "    return encoded_data, transformers_data\n",
    "\n",
    "#disc_data, pipeline_data = discretize(data, variables, icat=None, icont=[0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сборка таблиц усл. вероятностей по БС с градациями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_cpds(bn_info, distributions, n_states_map):\n",
    "    cpds = list()\n",
    "    for index, row in bn_info.iterrows():\n",
    "        feat = row[\"name\"].name\n",
    "        if len(row[\"parents\"]) == 0:\n",
    "            # cpd is just a pd\n",
    "            cpd = TabularCPD(feat, n_states_map[feat], [[e] for e in distributions[feat][\"cprob\"]])\n",
    "            cpds.append(cpd)\n",
    "        else:\n",
    "            cpd_list = [probs for probs in distributions[feat][\"cprob\"].values()]\n",
    "            #cpd_list = [probs for i, probs in distributions[feat][\"cprob\"].items() if i[0]!=\"[\"]\n",
    "            #print(cpd_list)\n",
    "            nrows = len(cpd_list)\n",
    "            ncols = len(cpd_list[0])\n",
    "            cpd_list = [[cpd_list[i][j] for i in range(nrows)] for j in range(ncols)]\n",
    "            #print(feat, row[\"parents\"])\n",
    "            #print(cpd_list)\n",
    "            cpd = TabularCPD(feat, n_states_map[feat], cpd_list, evidence=row[\"parents\"], evidence_card=[n_states_map[p] for p in row[\"parents\"]])\n",
    "            cpds.append(cpd)\n",
    "    return cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sampling(data,\n",
    "                       d_dict,# словарь списков фактор-градация\n",
    "                       b_sample_size,\n",
    "                       metrics_list, trials=1000, alpha=0, incl_random_removal=False,\n",
    "                       mode='regr',\n",
    "                       drop_mode='random',\n",
    "                       reference='bn',\n",
    "                       incl_test=False,\n",
    "                       test_size=0.3,\n",
    "                       stratify_tts=True):\n",
    "    \n",
    "    n_ref=np.inf\n",
    "\n",
    "    metrics_results={\n",
    "        k: [list() for _ in range(len(metrics_list))] for k in d_dict.keys()\n",
    "    }\n",
    "    metrics_results['init'] = [list() for _ in range(len(metrics_list))]\n",
    "\n",
    "    \n",
    "\n",
    "    if incl_random_removal:\n",
    "        metrics_results['random'] = [list() for _ in range(len(metrics_list))]\n",
    "\n",
    "    metrics_results_test = {k: [list() for _ in range(len(metrics_list))] for k in metrics_results.keys()}\n",
    "\n",
    "    n_dropped_stats={k: list() for k in metrics_results.keys()}\n",
    "\n",
    "    #пробуем побутсрапировать выборку, чтобы оценить значимость различий в ошибках регрессии\n",
    "    for i in tqdm(range(trials)):\n",
    "        r_seed = 42+i\n",
    "        np.random.seed(r_seed)\n",
    "        #indexes = np.random.choice(data.index, size=b_sample_size)\n",
    "        #bsample = data.loc[indexes].reset_index()[data.columns]\n",
    "        if not incl_test:\n",
    "            bsample = data.sample(n=b_sample_size, replace=False).reset_index()[data.columns]\n",
    "        else:\n",
    "            bsample_train, b_sample_test = train_test_split(data, random_state=r_seed,\n",
    "                                                            test_size=test_size,\n",
    "                                                            stratify=data[target] if stratify_tts else None)\n",
    "            bsample = bsample_train.sample(n=b_sample_size, replace=True).reset_index()[data.columns]\n",
    "        \n",
    "        model_base = copy(model)\n",
    "        model_base.fit(bsample[features], bsample[target])\n",
    "\n",
    "        if mode=='regr':\n",
    "            y_pred = model_base.predict(bsample[features]) # depends on task (regr/classif)\n",
    "        else:\n",
    "            y_pred = model_base.predict_proba(bsample[features])[:, 1] # depends on task (regr/classif)\n",
    "\n",
    "        data_errors = bsample.copy(deep=True)\n",
    "        if mode=='regr':\n",
    "            data_errors[\"ape_error\"] = np.abs((bsample[target]-y_pred)/bsample[target])\n",
    "        else:\n",
    "            #inconf scode\n",
    "            data_errors[\"inconf_error\"]=(1-y_pred)*bsample[target]+(y_pred)*(1-bsample[target])\n",
    "\n",
    "\n",
    "        data_errors.drop(columns=[target], inplace=True)\n",
    "\n",
    "        bsample_disc = pd.DataFrame(pipeline_data[\"transformer\"].transform(data_errors), columns=data_errors.columns)\n",
    "        \n",
    "        bsample_disc = bsample_disc.reindex(index=data_errors.index)\n",
    "        \n",
    "        #print(pipeline_data[\"transformer\"].transform(data_errors).shape[0])\n",
    "        iterlist = [reference]+[x for x in metrics_results.keys() if x != reference]\n",
    "\n",
    "        for g in iterlist:\n",
    "            mask = False\n",
    "            if g == 'init':\n",
    "                mask = None\n",
    "                samp = bsample\n",
    "            elif g == 'random':\n",
    "                mask=None\n",
    "                indexes_to_drop = np.random.choice(bsample.index, size=n_ref, replace=False)\n",
    "                samp = bsample.drop(index=indexes_to_drop)\n",
    "            else:\n",
    "                mask=False\n",
    "                for feat, cat in zip(d_dict[g][0], d_dict[g][1]):\n",
    "                    mask = mask | (bsample_disc[feat]==cat)\n",
    "                \n",
    "                if drop_mode == 'random':\n",
    "                    indexes_to_drop = np.random.choice(bsample[mask].index, size=int(np.floor(bsample[mask].shape[0]*(1-alpha))), replace=False)\n",
    "                elif drop_mode == 'metric':\n",
    "                    if mode=='regr':\n",
    "                        errors = data_errors[mask]['ape_error']\n",
    "                    else:\n",
    "                        #inconf scode\n",
    "                        #print(g)\n",
    "                        #print(mask.index, data_errors.index)\n",
    "                        #print(bsample.shape[0], bsample_disc.shape[0], data_errors.shape[0], mask.shape, indexes.shape[0])\n",
    "                        errors = data_errors[mask][\"inconf_error\"]\n",
    "\n",
    "                    errors_sorted = errors.sort_values(ascending=False)\n",
    "                    size = min(n_ref, int(np.floor(errors.shape[0]*(1-alpha))))\n",
    "\n",
    "                    # т.к. подходы могут отбрасывать разное кол-во наблюдений, получаемый результат по метрикам будет разным из-за этого\n",
    "\n",
    "                    #thresh = errors_sorted[:size].min()\n",
    "                    #indexes_to_drop = errors[errors>=thresh].index\n",
    "                    thresh = errors_sorted[-size:].max()\n",
    "                    indexes_to_drop = errors[errors<thresh].index\n",
    "                \n",
    "                samp = bsample.drop(index=indexes_to_drop)\n",
    "                if g==reference:\n",
    "                    n_ref=indexes_to_drop.shape[0]\n",
    "                    \n",
    "                n_dropped_stats[g].append(indexes_to_drop.shape[0])\n",
    "        # --\n",
    "            \n",
    "            X1, y1 = samp[features], samp[target]\n",
    "\n",
    "            model1 = copy(model)\n",
    "            model1.fit(X1, y1)  \n",
    "\n",
    "            def calculate_metrics(model, X_data, y_data):\n",
    "                dict_m = {}\n",
    "                if mode=='regr':\n",
    "                    y1_pred = model.predict(X_data) # depends on task (regr/classif)\n",
    "                else:\n",
    "                    y1_pred = model.predict_proba(X_data)[:, 1] # depends on task (regr/classif)\n",
    "\n",
    "                for k, metric in enumerate(metrics_list):\n",
    "                    dict_m[k] = metric(y_data, y1_pred)\n",
    "\n",
    "                return dict_m\n",
    "\n",
    "\n",
    "\n",
    "            train_res = calculate_metrics(model1, X1, y1)\n",
    "            for k, metric in enumerate(metrics_list):\n",
    "                metrics_results[g][k].append(train_res[k])\n",
    "\n",
    "            if incl_test:\n",
    "                test_res = calculate_metrics(model1, b_sample_test[features], b_sample_test[target])\n",
    "                for k, metric in enumerate(metrics_list):\n",
    "                    metrics_results_test[g][k].append(test_res[k])\n",
    "\n",
    "    return_value = {'metrics': metrics_results,\n",
    "             'n_dropped': n_dropped_stats,\n",
    "             'avg_n_dropped': {k: sum(v)/len(v) if len(v) >0 else -1 for k, v in n_dropped_stats.items()}}\n",
    "    \n",
    "    if incl_test:\n",
    "        return_value['metrics_test'] = metrics_results_test\n",
    "\n",
    "    return return_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
